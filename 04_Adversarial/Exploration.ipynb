{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Adversarial Exploration\n",
    "\n",
    "In this chapter I want to explore the possibilities for generating an adversarial example image that cannot be  classified correctly. For example, we might have an image of a car and we want the neural network to misclassify it as a pedestrian or any other type of object based on the outputs of the neural network. \n",
    "\n",
    "To generate an adversarial example we will need get the gradient of the image with respect to the wrong classification so that we can slightly change the image. If we repeat that step over and over again we should yield an image that still looks like the original one but yields a wrong classification\n",
    "\n",
    "#### Installation\n",
    "For this chapter I will use PyTorch again because I really like PyTorch and use it on a day to day basis. Use the following conda command to install pytorch on your machine:\n",
    "\n",
    "```shell\n",
    "conda install pytorch torchvision -c pytorch\n",
    "```\n",
    "\n",
    "Furthermore, I will use a pretrained model (e.g. AlexNet) for image classification. You can download the weights for a trained AlexNet under the following link and store it in the `data` folder within the subfolder `04_Adversarial`. You could also use the pretrained flag but that will give you now control over the weights that the model is actually using.\n",
    "\n",
    "https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision.models import AlexNet\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained AlexNet\n",
    "\n",
    "We first need to load the pretrained weights so that we can initialize the model with the weights. Otherwise you would need to retrain the model so that it achieves good classification outputs. After that I wanted to see if the model really works so I decided the forward pass an image through the network. But before I was able to do that I had to figure out how the output looks like and what class predictions it can generate (e.g. car, train, bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "pretrained_weights = torch.load('./data/alexnet-owt-4df8aa71.pth')\n",
    "model.load_state_dict(pretrained_weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to be trained on the ImageNet data because there are 1000 output features. To get the actual \"probability\" for each of the 1000 classes we probably still need to pass the logits through a softmax activation. Logits describe the values of the neurons of the last layer before the final activation (e.g. softmax) occurs. Furthermore, you can take a look at the documentation which will also tell you that there are 1000 output classes from the ImageNet training data:  \n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/models/alexnet.html#alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
     ]
    }
   ],
   "source": [
    "cifar10_data = CIFAR10(root=\"./data/\" ,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "1. It seems to be quite easy to generate an adversarial example. You do not need a lot of computing power especially if you only want to generate a single adversarial example. However, I would like to explore some other techniques that are more sophisticated like generating a path that makes object disappear. For that I would like to use YOLO which is one of the SOTA object detection models.\n",
    "\n",
    "2. The pretrained PyTorch models and Datasets are very handy and easy to use. Especially if you want to do something like object detection it might make sense to use a pretrained vision model. This type of learning is called transfer learning because our pretrained model already knows how objects might look like and the first few layers for feature extraction are already trained. This would allow our more advanced model to use that kind of representation to solve its own task. Finally, this might save you a lot of training time and compute. Thus, keep the following imports in mind:\n",
    "\n",
    "```python\n",
    "from torchvision.models import AlexNet\n",
    "from torchvision.datasets import CIFAR10\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
